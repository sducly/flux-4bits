# üöÄ Projet : Quantization Flux 4-bits pour Petits GPU

Bienvenue dans ce projet exp√©rimental ! L'objectif ici est de vous permettre de **tester et d'ex√©cuter des mod√®les bas√©s sur l'architecture Flux** en utilisant une **quantization 4-bits ultra-l√©g√®re**, sp√©cifiquement con√ßue pour les **GPU avec des ressources VRAM limit√©es** (y compris les puces Apple Silicon comme M1, M2, M3).

Dites adieu aux erreurs de m√©moire lors de l'ex√©cution de mod√®les gourmands sur votre mat√©riel modeste !

## ‚ú® Fonctionnalit√©s Cl√©s

- **Quantization 4-bits Ultra-L√©g√®re :** R√©duction drastique de l'empreinte m√©moire des mod√®les pour tenir sur de petits GPU.
- **Optimis√© Flux :** Se concentre sur l'exp√©rimentation avec les mod√®les bas√©s sur l'architecture Flux.
- **D√©marrage Simplifi√© :** Configurez et lancez le projet rapidement gr√¢ce √† `make`.
- **Support Apple Silicon (M1/M2/M3) :** Instructions incluses pour utiliser le backend Metal.

## üìã Pr√©requis

Avant de commencer, assurez-vous que les outils suivants sont install√©s sur votre syst√®me :

- [**Docker**](https://docs.docker.com/get-docker/) : Pour construire et ex√©cuter le conteneur de l'application.
- [**Make**](https://www.gnu.org/software/make/) : Pour automatiser les √©tapes d'initialisation et de d√©marrage.
- **Cl√© API Hugging Face :** N√©cessaire pour t√©l√©charger les mod√®les. Si vous n'en avez pas, cr√©ez-en une ici : [Vos Tokens d'Acc√®s Hugging Face](https://huggingface.co/settings/tokens).

## üöÄ D√©marrage Rapide

Suivez ces √©tapes simples pour mettre en place et lancer l'environnement :

1.  **Configuration de l'environnement :**
    Cr√©ez le fichier de configuration de votre environnement local en copiant l'exemple fourni :

    ```bash
    cp .env.example .env
    ```

2.  **Ajout de votre Cl√© Hugging Face :**
    Ouvrez le fichier `.env` que vous venez de cr√©er et ajoutez votre cl√© API Hugging Face √† la ligne `HF_API_KEY`.

    ```dotenv
    # Exemple de contenu de votre fichier .env
    HF_API_KEY=votre_super_cle_huggingface_ici
    ```

    N'oubliez pas que vous pouvez trouver ou g√©rer votre cl√© ici : [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

3.  **Initialisation du Projet :**
    Lancez la commande `make init`. Cette √©tape va construire l'image Docker n√©cessaire pour le projet.

    ```bash
    make init
    ```

    _Cette commande peut prendre un certain temps lors de la premi√®re ex√©cution car elle t√©l√©charge les d√©pendances et construit l'image Docker._

4.  **Lancement de l'Application :**
    Une fois l'initialisation termin√©e, vous pouvez lancer l'application principale avec la commande `make start`.
    ```bash
    make start
    ```
    Cette commande d√©marre le conteneur Docker et ex√©cute le script Python principal (`flux.py`) qui g√©n√®re l'image.

## üîß Am√©lioration de la R√©solution et de la Qualit√©

Le script de g√©n√©ration d'image (`flux.py`) utilise plusieurs param√®tres qui influencent la taille et la qualit√© de l'image finale. Vous pouvez les modifier directement dans ce fichier Python pour exp√©rimenter.

Voici les param√®tres cl√©s que vous pourriez vouloir ajuster dans `flux.py` :

1.  **Mod√®le d'Upscale (`model_path`) :**

    - Dans la fonction `upscale_image`, la ligne `model_path = os.path.join("models", "modelx4.ort")` sp√©cifie le mod√®le ONNX utilis√© pour l'upscaling.
    - Par d√©faut, il utilise `modelx4.ort` pour un facteur d'agrandissement de x4.
    - **Pour utiliser un mod√®le x2**, changez cette ligne en :
      ```python
      model_path = os.path.join("models", "modelx2.ort")
      ```
    - _Note : Assurez-vous d'avoir le fichier `modelx2.ort` dans le dossier `models/` de votre projet._

2.  **Taille de l'Image de Base :**

    - Dans la fonction `generate_image`, les lignes `base_image_width = int(image_with // 4)` et `base_image_height = int(image_height // 4)` d√©finissent les dimensions de l'image g√©n√©r√©e par le pipeline Flux _avant_ l'upscaling.
    - Elles divisent les dimensions finales souhait√©es (`image_with`, `image_height`) par 4.
    - **Pour g√©n√©rer une image de base plus grande** (ce qui, combin√© √† un upscale x2, peut donner une meilleure qualit√©), changez la division par 4 en division par 2 :
      ```python
      base_image_width = int(image_with // 2)
      base_image_height = int(image_height // 2)
      ```
    - _Attention : Augmenter la taille de l'image de base consomme plus de VRAM sur votre GPU._

3.  **Nombre d'√âtapes d'Inf√©rence (`num_inference_steps`) :**
    - La variable `num_inference_steps` (d√©finie en d√©but de script et utilis√©e dans `pipe_args`) contr√¥le le nombre d'√©tapes que le pipeline Flux utilise pour g√©n√©rer l'image de base.
    - Un nombre d'√©tapes plus √©lev√© peut potentiellement am√©liorer la qualit√© et les d√©tails de l'image, mais cela augmente aussi le temps de g√©n√©ration.
    - **Pour augmenter le nombre d'√©tapes**, modifiez la valeur de cette variable. Par exemple, pour passer de 28 √† 40 √©tapes :
      ```python
      num_inference_steps=40
      ```

**En combinant ces modifications (utiliser `modelx2.ort`, diviser la taille de base par 2, et augmenter `num_inference_steps`), vous g√©n√©rerez une image de base deux fois plus grande qui sera ensuite upscal√©e par un facteur de 2, r√©sultant en une image finale de la m√™me dimension cible (`image_with` x `image_height`), mais potentiellement avec une meilleure qualit√© per√ßue gr√¢ce √† l'image de base plus grande et aux √©tapes d'inf√©rence suppl√©mentaires.**

N'h√©sitez pas √† exp√©rimenter avec ces valeurs pour trouver le meilleur √©quilibre entre qualit√©, vitesse et consommation de m√©moire pour votre configuration mat√©rielle.

## üçé Note pour les utilisateurs de Mac (Apple Silicon - M1/M2/M3)

Ce projet est con√ßu pour fonctionner sur des GPU avec des ressources limit√©es, y compris les puces Apple Silicon.

Pour vous assurer que PyTorch utilise correctement le backend Metal (qui remplace CUDA sur Mac) :

1.  **V√©rifiez votre installation de PyTorch :** Assurez-vous d'avoir install√© la version de PyTorch compatible avec 'mps' (Metal Performance Shaders). L'installation via `pip install torch torchvision torchaudio` dans un environnement compatible (comme dans votre Dockerfile si vous adaptez l'image de base ou si vous l'installez localement) devrait g√©rer cela.

---

Bonne experimentation avec la quantization 4-bits ! ‚ú®
